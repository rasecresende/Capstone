{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d5ea9b4-0c01-47dc-92f5-2251bd94af76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from re import sub\n",
    "import multiprocessing\n",
    "from unidecode import unidecode\n",
    "\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.test.utils import get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "\n",
    "from time import time \n",
    "from collections import defaultdict\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "import stop_words\n",
    "from stop_words import get_stop_words\n",
    "\n",
    "import logging  # Setting up the loggings to monitor gensim\n",
    "logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt= '%H:%M:%S', level=logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "550d645e-a678-4ef6-afc4-a0464f179553",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data/tweets_df.csv')\n",
    "df = df.iloc[: , 1:] #dropping the first column of indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "deafe781-2775-489e-9349-180cb9c7f415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Text</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Source</th>\n",
       "      <th>entity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-10-30 23:59:46+00:00</td>\n",
       "      <td>$BEST inc short float is 24.80%\\n\\nWhen is the...</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
       "      <td>$GME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-10-30 23:55:43+00:00</td>\n",
       "      <td>I THINK EVERYONE INVESTED IN $AMC OR $GME SHOU...</td>\n",
       "      <td>491</td>\n",
       "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
       "      <td>$GME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-10-30 23:55:13+00:00</td>\n",
       "      <td>@2killmokingbird @shortdestroyer @traintickets...</td>\n",
       "      <td>5</td>\n",
       "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
       "      <td>$GME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-10-30 23:54:39+00:00</td>\n",
       "      <td>$amc $gme https://t.co/CJoSARve9v</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>$GME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-10-30 23:53:48+00:00</td>\n",
       "      <td>A Massive $Brandable #Domain For Sale:\\n\\nhttp...</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
       "      <td>$GME</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Date  \\\n",
       "0  2021-10-30 23:59:46+00:00   \n",
       "1  2021-10-30 23:55:43+00:00   \n",
       "2  2021-10-30 23:55:13+00:00   \n",
       "3  2021-10-30 23:54:39+00:00   \n",
       "4  2021-10-30 23:53:48+00:00   \n",
       "\n",
       "                                                Text  Likes  \\\n",
       "0  $BEST inc short float is 24.80%\\n\\nWhen is the...      2   \n",
       "1  I THINK EVERYONE INVESTED IN $AMC OR $GME SHOU...    491   \n",
       "2  @2killmokingbird @shortdestroyer @traintickets...      5   \n",
       "3                  $amc $gme https://t.co/CJoSARve9v      1   \n",
       "4  A Massive $Brandable #Domain For Sale:\\n\\nhttp...      2   \n",
       "\n",
       "                                              Source entity  \n",
       "0  <a href=\"https://mobile.twitter.com\" rel=\"nofo...   $GME  \n",
       "1  <a href=\"https://mobile.twitter.com\" rel=\"nofo...   $GME  \n",
       "2  <a href=\"https://mobile.twitter.com\" rel=\"nofo...   $GME  \n",
       "3  <a href=\"http://twitter.com/download/android\" ...   $GME  \n",
       "4  <a href=\"https://mobile.twitter.com\" rel=\"nofo...   $GME  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ccb97f3-5f80-4e2f-aa25-b44e31ee3535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(92636, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74cdfb66-87bc-4870-ba9f-f8914623ee96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    $BEST inc short float is 24.80%\\n\\nWhen is the...\n",
       "1    I THINK EVERYONE INVESTED IN $AMC OR $GME SHOU...\n",
       "2        I sold a very infamous ticker the other da...\n",
       "3                                           $amc $gme \n",
       "4    A Massive $Brandable #Domain For Sale:\\n\\n \\nM...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dropping duplicates and resetting index\n",
    "df = df.drop_duplicates(['Text'])\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "def remove_pattern(input_txt, pattern):\n",
    "    r = re.findall(pattern, input_txt)\n",
    "    for i in r:\n",
    "        input_txt = re.sub(i, '', input_txt)        \n",
    "    return input_txt\n",
    "\n",
    "def clean_tweets(tweets):\n",
    "    #remove twitter Return handles (RT @xxx:)\n",
    "    tweets = np.vectorize(remove_pattern)(tweets, \"RT @[\\w]*:\") \n",
    "    \n",
    "    #remove twitter handles (@xxx)\n",
    "    tweets = np.vectorize(remove_pattern)(tweets, \"@[\\w]*\")\n",
    "    \n",
    "    #remove URL links (httpxxx)\n",
    "    tweets = np.vectorize(remove_pattern)(tweets, \"https?://[A-Za-z0-9./]*\")\n",
    "    \n",
    "    #remove special characters, numbers, punctuations (except for #)\n",
    "    tweets = np.core.defchararray.replace(tweets, \"[^a-zA-Z]\", \" \")\n",
    "    \n",
    "    return tweets\n",
    "\n",
    "df['Text'] = clean_tweets(df['Text'])\n",
    "df['Text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a93b9cd3-3cf3-48c0-857c-6ed465b388b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words1 = set(stopwords.words('english')) #from nltk corpus\n",
    "stop_words2 = list(get_stop_words('en')) #from stop_words library\n",
    "tickers = ['$GME', '$AMC', '$UPST', '$GOOGL', '$AAPL', '$MSFT', '$SAVA', '$AMZN', '$BB', '$BBY']\n",
    "\n",
    "#removing stopwords and tickers from text\n",
    "df['Text'] = df['Text'].apply(lambda x: ' '.join(\n",
    "    [word for word in x.split() if word not in (stop_words1) and (stop_words2)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19a6e826-533a-4fe7-8b2b-49d6006e2df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179\n",
      "174\n"
     ]
    }
   ],
   "source": [
    "print(len(stop_words1))\n",
    "print(len(stop_words2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24d85d4d-ab39-4efd-9432-aced58aeae40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_word_list(text):\n",
    "    text = str(text)\n",
    "    text = text.lower()\n",
    "\n",
    "    # extra cleaning\n",
    "    text = sub(r\"[^A-Za-z0-9^,!?.\\/'+]\", \" \", text)\n",
    "    text = sub(r\"\\+\", \" plus \", text)\n",
    "    text = sub(r\",\", \" \", text)\n",
    "    text = sub(r\"\\.\", \" \", text)\n",
    "    text = sub(r\"!\", \" ! \", text)\n",
    "    text = sub(r\"\\?\", \" ? \", text)\n",
    "    text = sub(r\"'\", \" \", text)\n",
    "    text = sub(r\":\", \" : \", text)\n",
    "    text = sub(r\"\\s{2,}\", \" \", text)\n",
    "\n",
    "    text = text.split()\n",
    "\n",
    "    return text  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5dc36304-4c8e-4bba-a38a-beb59313417e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Text = df.Text.apply(lambda x: text_to_word_list(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f62467ce-420f-4aa1-8136-408a71c60cda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Text</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Source</th>\n",
       "      <th>entity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-10-30 23:59:46+00:00</td>\n",
       "      <td>[best, inc, short, float, 24, 80, when, squeez...</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
       "      <td>$GME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-10-30 23:55:43+00:00</td>\n",
       "      <td>[i, think, everyone, invested, in, amc, or, gm...</td>\n",
       "      <td>491</td>\n",
       "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
       "      <td>$GME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-10-30 23:55:13+00:00</td>\n",
       "      <td>[i, sold, infamous, ticker, day, 350, profit, ...</td>\n",
       "      <td>5</td>\n",
       "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
       "      <td>$GME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-10-30 23:54:39+00:00</td>\n",
       "      <td>[amc, gme]</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>$GME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-10-30 23:53:48+00:00</td>\n",
       "      <td>[a, massive, brandable, domain, for, sale, mar...</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
       "      <td>$GME</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Date  \\\n",
       "0  2021-10-30 23:59:46+00:00   \n",
       "1  2021-10-30 23:55:43+00:00   \n",
       "2  2021-10-30 23:55:13+00:00   \n",
       "3  2021-10-30 23:54:39+00:00   \n",
       "4  2021-10-30 23:53:48+00:00   \n",
       "\n",
       "                                                Text  Likes  \\\n",
       "0  [best, inc, short, float, 24, 80, when, squeez...      2   \n",
       "1  [i, think, everyone, invested, in, amc, or, gm...    491   \n",
       "2  [i, sold, infamous, ticker, day, 350, profit, ...      5   \n",
       "3                                         [amc, gme]      1   \n",
       "4  [a, massive, brandable, domain, for, sale, mar...      2   \n",
       "\n",
       "                                              Source entity  \n",
       "0  <a href=\"https://mobile.twitter.com\" rel=\"nofo...   $GME  \n",
       "1  <a href=\"https://mobile.twitter.com\" rel=\"nofo...   $GME  \n",
       "2  <a href=\"https://mobile.twitter.com\" rel=\"nofo...   $GME  \n",
       "3  <a href=\"http://twitter.com/download/android\" ...   $GME  \n",
       "4  <a href=\"https://mobile.twitter.com\" rel=\"nofo...   $GME  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e4e118a-0b40-4a04-aa31-0262f4009f99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79821, 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a365830-d350-496f-bc02-efe0287876ce",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95cab830-7413-4ac9-8ee0-c55a6ac4002e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 18:53:24: collecting all words and their counts\n",
      "INFO - 18:53:24: PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
      "INFO - 18:53:26: PROGRESS: at sentence #50000, processed 1005862 words and 510111 word types\n",
      "INFO - 18:53:27: collected 753154 token types (unigram + bigrams) from a corpus of 1589798 words and 79821 sentences\n",
      "INFO - 18:53:27: merged Phrases<753154 vocab, min_count=1, threshold=10.0, max_vocab_size=40000000>\n",
      "INFO - 18:53:27: Phrases lifecycle event {'msg': 'built Phrases<753154 vocab, min_count=1, threshold=10.0, max_vocab_size=40000000> in 2.27s', 'datetime': '2021-12-04T18:53:27.008778', 'gensim': '4.1.2', 'python': '3.8.12 (default, Oct 12 2021, 03:01:40) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19043-SP0', 'event': 'created'}\n",
      "INFO - 18:53:27: exporting phrases from Phrases<753154 vocab, min_count=1, threshold=10.0, max_vocab_size=40000000>\n",
      "INFO - 18:53:28: FrozenPhrases lifecycle event {'msg': 'exported FrozenPhrases<53051 phrases, min_count=1, threshold=10.0> from Phrases<753154 vocab, min_count=1, threshold=10.0, max_vocab_size=40000000> in 1.79s', 'datetime': '2021-12-04T18:53:28.812682', 'gensim': '4.1.2', 'python': '3.8.12 (default, Oct 12 2021, 03:01:40) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19043-SP0', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "sent = [row for row in df.Text]\n",
    "phrases = Phrases(sent, min_count=1, progress_per=50000)\n",
    "bigram = Phraser(phrases)\n",
    "sentences = bigram[sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6a86299-3a29-4de3-82be-8e9906cabda6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 18:53:36: Word2Vec lifecycle event {'params': 'Word2Vec(vocab=0, vector_size=300, alpha=0.03)', 'datetime': '2021-12-04T18:53:36.095625', 'gensim': '4.1.2', 'python': '3.8.12 (default, Oct 12 2021, 03:01:40) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19043-SP0', 'event': 'created'}\n",
      "INFO - 18:53:36: collecting all words and their counts\n",
      "INFO - 18:53:36: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO - 18:53:37: PROGRESS: at sentence #50000, processed 839319 words, keeping 68620 word types\n",
      "INFO - 18:53:37: collected 89789 word types from a corpus of 1322194 raw words and 79821 sentences\n",
      "INFO - 18:53:37: Creating a fresh vocabulary\n",
      "INFO - 18:53:38: Word2Vec lifecycle event {'msg': 'effective_min_count=3 retains 37760 unique words (42.054149171947564%% of original 89789, drops 52029)', 'datetime': '2021-12-04T18:53:38.112252', 'gensim': '4.1.2', 'python': '3.8.12 (default, Oct 12 2021, 03:01:40) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19043-SP0', 'event': 'prepare_vocab'}\n",
      "INFO - 18:53:38: Word2Vec lifecycle event {'msg': 'effective_min_count=3 leaves 1245407 word corpus (94.19245587258753%% of original 1322194, drops 76787)', 'datetime': '2021-12-04T18:53:38.112252', 'gensim': '4.1.2', 'python': '3.8.12 (default, Oct 12 2021, 03:01:40) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19043-SP0', 'event': 'prepare_vocab'}\n",
      "INFO - 18:53:38: deleting the raw counts dictionary of 89789 items\n",
      "INFO - 18:53:38: sample=1e-05 downsamples 4142 most-common words\n",
      "INFO - 18:53:38: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 475719.6193078323 word corpus (38.2%% of prior 1245407)', 'datetime': '2021-12-04T18:53:38.384085', 'gensim': '4.1.2', 'python': '3.8.12 (default, Oct 12 2021, 03:01:40) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19043-SP0', 'event': 'prepare_vocab'}\n",
      "INFO - 18:53:38: estimated required memory for 37760 words and 300 dimensions: 109504000 bytes\n",
      "INFO - 18:53:38: resetting layer weights\n",
      "INFO - 18:53:38: Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2021-12-04T18:53:38.839578', 'gensim': '4.1.2', 'python': '3.8.12 (default, Oct 12 2021, 03:01:40) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19043-SP0', 'event': 'build_vocab'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build vocab: 0.05 mins\n"
     ]
    }
   ],
   "source": [
    "w2v_model = Word2Vec(min_count=3,\n",
    "                     window=4,\n",
    "                     vector_size=300,\n",
    "                     sample=1e-5, \n",
    "                     alpha=0.03, \n",
    "                     min_alpha=0.0007, \n",
    "                     negative=20,\n",
    "                     workers=multiprocessing.cpu_count()-1)\n",
    "\n",
    "start = time()\n",
    "\n",
    "w2v_model.build_vocab(sentences, progress_per=50000)\n",
    "\n",
    "print('Time to build vocab: {} mins'.format(round((time() - start) / 60, 2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9cb3779-df63-4a55-8211-2db34a04b1da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 18:53:41: Word2Vec lifecycle event {'fname_or_handle': 'word2vec.model', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2021-12-04T18:53:41.429437', 'gensim': '4.1.2', 'python': '3.8.12 (default, Oct 12 2021, 03:01:40) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19043-SP0', 'event': 'saving'}\n",
      "INFO - 18:53:41: storing np array 'vectors' to word2vec.model.wv.vectors.npy\n",
      "INFO - 18:53:41: storing np array 'syn1neg' to word2vec.model.syn1neg.npy\n",
      "INFO - 18:53:41: not storing attribute cum_table\n",
      "INFO - 18:53:41: saved word2vec.model\n"
     ]
    }
   ],
   "source": [
    "w2v_model.save(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b396652b-b566-4445-b099-49ad17186247",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Data/lemma_tweets_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "caae3fa2-5043-471a-9679-af9ec417c675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('their', 0.25109899044036865),\n",
       " ('rt_nio', 0.2398056983947754),\n",
       " ('plug_ada', 0.23929455876350403),\n",
       " ('marching', 0.23512135446071625),\n",
       " ('btx', 0.23292715847492218),\n",
       " ('bidu_baba', 0.2291838526725769),\n",
       " ('introduces', 0.21706560254096985),\n",
       " ('lets_see', 0.21530334651470184),\n",
       " ('curevac_cvac', 0.2105555534362793),\n",
       " ('tgls', 0.2039554864168167)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(negative=[\"bearish\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "17cd6a98-9c38-4bee-afd7-8523e347398a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03167111"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.similarity(\"bearish\", 'buy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0853e7-6cca-41e6-a4f4-c3a6110f0dd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67117f5-9449-4b4f-a725-1d1d6e8099e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aab5bdb-5ac0-46a7-83fa-4009b4d76598",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
